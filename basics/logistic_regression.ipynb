{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05e894e1",
   "metadata": {},
   "source": [
    "<div align=\"right\">Author: DelusionaL<br>Date: 10/04/2021</div>\n",
    "\n",
    "# Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "900b9f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d7a299f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    s = 1/(1+np.exp(-x))    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68c0e964",
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagate(w,b,X,Y):\n",
    "    \"\"\"\n",
    "    args:\n",
    "    w = (n, 1) vector\n",
    "    b = 0\n",
    "    X = (n, no of examples=m) vector\n",
    "    Y = (1, no of examples=m) vector of (1 or 0)\n",
    "    \n",
    "    return:\n",
    "    grads = {dw,db} derivatives of w and b\n",
    "    cost = estimated cost\n",
    "    \"\"\"\n",
    "    m = X.shape[1]\n",
    "    \n",
    "    # forward propagation\n",
    "    A = sigmoid(np.dot(w.T, X) + b) # (1,m)\n",
    "    cost = -(1/m)*np.sum(Y*np.log(A)+(1-Y)*np.log(1-A))\n",
    "    \n",
    "    # backward propagation\n",
    "    dz = A - Y\n",
    "    dw = 1/m*(np.dot(X,dz.T))\n",
    "    db = 1/m*(np.sum(dz))\n",
    "    \n",
    "    grads = {\n",
    "        \"dw\": dw,\n",
    "        \"db\": db\n",
    "    }\n",
    "    \n",
    "    return grads, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6198a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(w,b,X,Y,learning_rate=0.003,num_iter=2000):\n",
    "    \"\"\"\n",
    "    args:\n",
    "    w = (n, 1) vector\n",
    "    b = 0\n",
    "    X = (n, no of examples=m) vector\n",
    "    Y = (1, no of examples=m) vector of (1 or 0)\n",
    "    learning_rate = alpha\n",
    "    num_iter = optimize w,b for this iteration\n",
    "    \n",
    "    return:\n",
    "    params = {w,b} optimized value of w and b\n",
    "    grads = {dw,db} derivatives of w and b\n",
    "    cost = estimated cost\n",
    "    \"\"\"\n",
    "    \n",
    "    for i in range(num_iter):\n",
    "        grads, cost = propagate(w,b,X,Y)\n",
    "        \n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "        \n",
    "        w = w - learning_rate*dw\n",
    "        b = b - learning_rate*db\n",
    "        \n",
    "    \n",
    "    params = {\n",
    "        'w': w,\n",
    "        'b': b\n",
    "    }\n",
    "    grads = {\n",
    "        'dw': dw,\n",
    "        'db': db\n",
    "    }\n",
    "    \n",
    "    return params, grads, cost\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05ea3f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(w,b,X):\n",
    "    \"\"\"\n",
    "    args:\n",
    "    w = (n, 1) vector\n",
    "    b = 0\n",
    "    X = (n, no of examples=m) vector\n",
    "    \n",
    "    return:\n",
    "    Y_prediction = predicted Y by learning\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    \n",
    "    Y_prediction = np.zeros((1,m))\n",
    "    \n",
    "    A = sigmoid(np.dot(w.T, X)+b)\n",
    "    \n",
    "    for i in range(m):\n",
    "        Y_prediction[0][i] = 1 if A[0][i]>0.5 else 0\n",
    "    \n",
    "    return Y_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5b7df73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x_train, y_train, x_test, y_test, num_iter=2000, learning_rate=0.003):\n",
    "    \"\"\"\n",
    "    args:\n",
    "    x_train = x of training set\n",
    "    y_train = truth label of train set\n",
    "    x_test = x of test set\n",
    "    y_test = truth label of test set\n",
    "    \n",
    "    return:\n",
    "    \n",
    "    \"\"\"\n",
    "    # initializing w and b with zeros\n",
    "    w = np.zeros((x_train.shape[0], 1))\n",
    "    b = 0\n",
    "    \n",
    "    parameters, grads, cost = optimize(w,b,x_train,y_train,learning_rate,num_iter)\n",
    "    \n",
    "    w = parameters['w']\n",
    "    b = parameters['b']\n",
    "    \n",
    "    # predict for train and test data set\n",
    "    y_train_predict = predict(w,b,x_train)\n",
    "    y_test_predict = predict(w,b,x_test)\n",
    "    \n",
    "    # estimated accuracy\n",
    "    accu_train = 100 - np.mean(np.abs(y_train_predict - y_train))*100\n",
    "    accu_test = 100 - np.mean(np.abs(y_test_predict - y_test))*100\n",
    "    \n",
    "    print(f\"Train accuracy: {accu_train} %\")\n",
    "    print(f'Test accuracy: {accu_test} %')\n",
    "    \n",
    "    final_out = {\n",
    "        'w':w,\n",
    "        'b':b,\n",
    "        'cost':cost,\n",
    "        'y_pre_train': y_train_predict,\n",
    "        'y_pre_test': y_test_predict,\n",
    "        'learning_rate': learning_rate,\n",
    "        'num_iter': num_iter\n",
    "    }\n",
    "    \n",
    "    return final_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78763c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
